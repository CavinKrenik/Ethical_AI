<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Unethical Uses of AI ‚Äì Cavin Krenik</title>
  <link rel="stylesheet" href="../styles.css" />
</head>

<body>
  <div class="background-overlay">
    <nav class="navbar">
      <ul>
        <li><a href="../index.html">Home</a></li>
        <li><a href="ethical_uses.html">Ethical Uses</a></li>
        <li><a href="unethical.html">Unethical Uses</a></li>
        <li><a href="use_example.html">Examples</a></li>
        <li><a href="ai_tips.html">AI Tips</a></li>
        <li><a href="resources.html">Resources</a></li>

      </ul>
    </nav>

    <header>
      <h1>Unethical Uses of AI in Education</h1>
      <p class="tagline">Understanding the risks and misuses of artificial intelligence</p>
    </header>
    <!-- AI Plagiarism visual: placed directly below the header -->
    <div style="display: flex; justify-content: center; margin: 1.5rem 0;">
      <img src="../images/aiplagar.png" alt="AI Plagiarism Example"
        style="max-width: 500px; width: 100%; height: auto; border-radius: 10px; box-shadow: 0 4px 24px rgba(0,0,0,0.13);">
    </div>

    <main>
      <div class="two-column-flex">
        <section class="transparent-box">
          <h2 class="center-heading">Ways Students Could Misuse AI in Education</h2>
          <ul>
            <li><strong>Academic Dishonesty and Plagiarism:</strong>
              <ul>
                <li><strong>Submitting AI-Generated Work as Their Own:</strong> Using AI tools (like ChatGPT, Claude,
                  Bard,
                  or specialized essay/code generators) to produce essays, reports, code, solutions to problems,
                  presentations, or other assignments and claiming authorship.</li>
                <li><strong>Automated Test/Quiz Taking:</strong> Employing AI bots or sophisticated AI tools to answer
                  questions during online assessments, bypassing the need for personal knowledge and understanding.</li>
                <li><strong>Inadequate Paraphrasing and Citation:</strong> Using AI paraphrasing tools to superficially
                  rewrite text from sources to avoid direct plagiarism detection, without truly understanding the
                  material or properly citing the original ideas.</li>
                <li><strong>Fabricating Sources or Data:</strong> Instructing AI to generate plausible-sounding but fake
                  references, research data, or quotes to support their work.</li>
                <li><strong>Deceptive Use in Collaborative Projects:</strong> Using AI to complete their individual
                  contributions to group work without the knowledge or consent of their peers, misrepresenting their
                  effort and learning.</li>
                <li><strong>Bypassing AI Detection Software:</strong> Actively seeking out and using techniques or tools
                  designed to make AI-generated content appear human-written to evade detection.</li>
              </ul>
            </li>
            <li><strong>Circumventing Learning and Skill Development:</strong>
              <ul>
                <li><strong>Over-reliance for Instant Answers:</strong> Using AI as a constant crutch for immediate
                  solutions, hindering the development of critical thinking, problem-solving skills, and deep
                  understanding of concepts.</li>
                <li><strong>Avoiding Effortful Learning Processes:</strong> Skipping essential learning stages like
                  research, drafting, and revision by offloading these tasks to AI.</li>
              </ul>
            </li>
            <li><strong>Deception and Impersonation:</strong>
              <ul>
                <li><strong>Automated Participation (Bots):</strong> Using AI bots to post generic comments or
                  participate
                  minimally in online discussion forums or virtual classes to feign engagement.</li>
                <li><strong>AI-Generated Avatars/Voice for Impersonation:</strong> (More advanced and less common
                  currently,
                  but a potential future misuse) Using AI to create fake profiles or mimic others in online
                  interactions.
                </li>
              </ul>
            </li>
            <li><strong>Creating an Unfair Advantage:</strong>
              <ul>
                <li><strong>Access to Sophisticated/Paid AI Tools:</strong> Utilizing advanced or subscription-based AI
                  tools
                  that provide a significant advantage over peers who do not have similar access due to financial or
                  other
                  constraints.</li>
              </ul>
            </li>
            <li><strong>Disruption and Harm:</strong>
              <ul>
                <li><strong>Generating Inappropriate or Harmful Content:</strong> Using AI to create and distribute
                  offensive, biased, harassing, or misleading content within the educational environment.</li>
                <li><strong>Creating Deepfakes:</strong> Generating fake images or videos of peers or educators for
                  malicious
                  purposes like bullying or defamation.</li>
                <!-- Spreading Misinformation -->
                <li><strong>Spreading Misinformation:</strong> Students may use AI to generate and disseminate false or
                  misleading information. This could involve creating fake news articles, crafting convincing but untrue
                  narratives about school events, or generating fabricated quotes from teachers or peers. The intent is
                  to deceive, manipulate opinions, damage reputations, or cause confusion and disruption within the
                  educational setting. AI's ability to produce highly credible text makes this a particularly potent
                  method of misuse.</li>
                <!-- Coordinating Disruptive Activities -->
                <li><strong>Coordinating Disruptive Activities:</strong> AI can be used to automate and scale disruptive
                  behaviors. Students might deploy AI-powered bots or scripts to flood online platforms (such as
                  discussion boards, chat rooms, or email inboxes) with spam or irrelevant content, making legitimate
                  communication difficult. AI can also be used to launch coordinated attacks, such as orchestrating
                  multiple accounts to post offensive content simultaneously, disrupt virtual lessons, or create
                  denial-of-service-like effects on school systems. Automation allows a single student or small group to
                  cause widespread chaos.</li>
              </ul>
            </li>
          </ul>
        </section>
        <section class="transparent-box">
          <h2 class="center-heading">Ways Teachers/Educators (and Institutions) Could Misuse AI</h2>
          <ul>
            <li><strong>Compromising Assessment Integrity and Fairness:</strong>
              <ul>
                <li><strong>Over-Reliance on AI Grading Without Oversight:</strong> Using AI tools to grade assignments
                  (especially complex ones like essays or projects) without adequate human review, potentially leading
                  to
                  inaccurate, biased, or context-blind assessments.</li>
                <li><strong>Using Biased AI Grading Tools:</strong> Implementing AI grading systems that have inherent
                  biases against specific demographic groups, writing styles, dialects, or students with disabilities,
                  resulting in unfair evaluations.</li>
                <li><strong>Lack of Transparency in AI Assessment:</strong> Failing to inform students how AI is used in
                  their assessment, what data is collected, and how they can appeal AI-driven decisions.</li>
              </ul>
            </li>
            <li><strong>Flawed Instruction and Curriculum Development:</strong>
              <ul>
                <li><strong>Distributing AI-Generated Content Without Vetting:</strong> Using AI to quickly create
                  lesson
                  plans, educational materials, or even exam questions that contain factual errors, outdated
                  information,
                  or biases, without thorough review and correction.</li>
                <li><strong>"Teaching to the Algorithm":</strong> Designing curriculum or teaching methodologies
                  primarily
                  to align with what AI tools can easily process or assess, rather than focusing on holistic student
                  development and critical thinking.</li>
                <li><strong>Replacing Human Interaction with AI:</strong> Over-relying on AI tutors or chatbots to the
                  detriment of meaningful student-teacher interaction, personalized feedback, and socio-emotional
                  support.
                </li>
              </ul>
            </li>
            <li><strong>Violating Student Privacy and Data Mismanagement:</strong>
              <ul>
                <li><strong>Implementing Overly Intrusive AI Surveillance:</strong> Using AI-powered proctoring or
                  monitoring tools that excessively track students (e.g., constant video/audio recording, biometric data
                  collection, keystroke logging) without clear justification, informed consent, or robust data security
                  measures.</li>
                <li><strong>Mishandling or Misusing Student Data:</strong> Collecting sensitive student data through AI
                  platforms and using it for purposes beyond direct educational improvement (e.g., commercial
                  exploitation, undisclosed profiling) or failing to secure it properly.</li>
                <li><strong>Lack of Transparency in Data Practices:</strong> Not clearly communicating to students and
                  parents how their data is collected, stored, used, shared, and protected by AI systems used in the
                  classroom.</li>
              </ul>
            </li>
            <li><strong>Perpetuating Inequity and Accessibility Issues:</strong>
              <ul>
                <li><strong>Mandating AI Tools with Unequal Access:</strong> Requiring the use of specific AI-powered
                  educational tools or platforms that are not equally accessible to all students due to cost, technology
                  requirements, or disabilities.</li>
                <li><strong>Deploying AI Not Designed for Accessibility:</strong> Using AI educational tools that are
                  not
                  compliant with accessibility standards, thereby creating barriers for students with disabilities.</li>
              </ul>
            </li>
            <li><strong>Eroding Professionalism and Autonomy:</strong>
              <ul>
                <li><strong>De-skilling Educators:</strong> Implementing AI systems in a way that overly automates
                  pedagogical tasks, reducing the professional judgment, creativity, and autonomy of teachers.</li>
                <li><strong>Making High-Stakes Decisions Solely Based on AI:</strong> Using AI-driven analytics for
                  critical
                  decisions about students (e.g., promotion, disciplinary action, learning disability identification)
                  without significant human oversight and contextual understanding.</li>
                <li><strong>Failing to Educate on Ethical AI Use:</strong> Not adequately preparing students (or fellow
                  educators) on the ethical implications, responsible use, and limitations of AI technologies.</li>
                <li><strong>Generating Biased Recommendations or Evaluations:</strong> Using AI to write student
                  recommendation letters or performance evaluations if the AI itself harbors biases or lacks nuanced
                  understanding.</li>
              </ul>
            </li>
          </ul>
        </section>
      </div>
      <!-- Case Study: AI Bots Steal Financial Aid in California -->
      <section class="transparent-box" style="max-width:700px; margin: 2rem auto;">
        <!-- Headline for the case study -->
        <h2>Case Study: AI Bots in California Steal Over $10 Million in Federal Financial Aid</h2>
        <p class="tagline"><em>A scam that uses AI to ‚Äúenroll‚Äù in community colleges to pocket student aid has
            skyrocketed in the Golden State and across the nation.</em></p>
        <p><strong>Autumn Billings | 4.30.2025 10:32 AM</strong></p>

        <!-- Full article content -->
        <p>
          If you're a community college student in California, there's a chance that at least one of your fellow
          students is actually an AI bot robbing taxpayers. Recent data from the California Community Colleges
          Chancellor's Office suggest that these bots have stolen more than $10 million in federal financial aid and
          upward of $3 million in state aid between March 2023 and March 2024.
        </p>
        <p>
          The scam is simple: Bots create AI-generated student profiles, apply for enrollment, and submit minimal online
          coursework‚Äîoften AI-generated‚Äîto stay enrolled long enough to receive federal and state aid disbursements
          intended for low-income students. The scammers are known as "Pell runners," who disappear after collecting the
          $7,400 federal grant.
        </p>
        <p>
          According to reporting by CalMatters, cases surged after restrictions around financial aid were loosened
          during the COVID-19 pandemic to make it easier for eligible students to access the one-time grants, which were
          provided to keep students enrolled. At the same time, coursework was moved online to comply with the state's
          lockdowns, opening the door to virtual scammers. As early as 2021, the Chancellor's Office estimated that 20
          percent of applications were fraudulent. Now, increasingly sophisticated AI tools have made the problem worse,
          and recent data suggest that around 34 percent of California community college applicants are fake. Despite
          California allocating over $150 million since 2022 toward cybersecurity to help authenticate students and
          combat fraud at community colleges, scammers have successfully stolen more financial aid with each passing
          year.
        </p>
        <p>
          California isn't the only state experiencing this problem. The FBI has investigated financial aid fraud cases
          across the country, including in Maryland, South Carolina, and Alabama. Nationwide, these crimes cost
          institutions over $100 million in 2023‚Äîa tenfold increase from the annual average before 2020.
        </p>
        <p>
          Making matters worse, each fake student enrolled in a class takes a spot away from a real student who needs
          credit to graduate, and instructors increasingly have to sniff out bots who weren't filtered out during the
          admissions process. Bots often impersonate homeless, undocumented, or former foster care students who do not
          need to verify their identity to enroll in a California community college and blame technological challenges
          for their inability to communicate with teachers. Additionally, the increased amount of AI-generated
          submissions by real students makes it difficult for instructors to identify scammers.
        </p>
        <p>
          Alarmed by the number of stolen taxpayer dollars, congressional Republicans from the Golden State have called
          for an investigation into their state's higher education system to "prevent further waste, fraud, and abuse"
          earlier this month.
        </p>
        <p>
          In a statement made to CalMatters, Chris Ferguson, a representative of the California Chancellor's Office,
          said the office has so far "not been contacted by the U.S. Department of Education or the U.S. Attorney
          General about an investigation." Ferguson also emphasized that a relatively low number of fraudulent students
          make it to the financial aid disbursement phase, making up only "about 0.21% in FY 2023-24."
        </p>
        <!-- Source attribution -->
        <p style="font-size:0.95em;color:#bbb;">
          Source: <a href="https://calmatters.org/education/2024/04/california-community-colleges-ai-bots-fraud/"
            target="_blank" rel="noopener">CalMatters</a> | Autumn Billings, 4.30.2025
        </p>
      </section>
    </main>

    <footer>
      <p>Created by Cavin Krenik | üìß <a href="mailto:cavinkrenik5@icloud.com">Contact Me</a></p>
    </footer>
  </div>
</body>

</html>

<!-- 

8888888888 888    888      d8b                   888             d8888     8888888     
888        888    888      Y8P                   888            d88888       888       
888        888    888                            888           d88P888       888       
8888888    888888 88888b.  888  .d8888b  8888b.  888          d88P 888       888       
888        888    888 "88b 888 d88P"        "88b 888         d88P  888       888       
888        888    888  888 888 888      .d888888 888        d88P   888       888       
888        Y88b.  888  888 888 Y88b.    888  888 888       d8888888888 d8b   888   d8b 
8888888888  "Y888 888  888 888  "Y8888P "Y888888 888      d88P     888 Y8P 8888888 Y8P 
                                                                                       
                                                                                       
                                                                                       -->