<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Unethical Uses of AI â€“ Cavin Krenik</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <div class="background-overlay">
    <nav class="navbar">
      <ul>
        <li><a href="../index.html">Home</a></li>
        <li><a href="../html/ethical_uses.html">Ethical Uses</a></li>
        <li><a href="../html/unethical.html">Unethical Uses</a></li>
        <li><a href="../html/use_example.html">Examples</a></li>
        <li><a href="../html/resources.html">Resources</a></li>
      </ul>
    </nav>

    <header>
      <h1>Unethical Uses of AI in Education</h1>
      <p class="tagline">Understanding the risks and misuses of artificial intelligence</p>
    </header>

    <main>
      <div class="two-column-flex">
        <section class="transparent-box">
          <h2 class="center-heading">Ways Students Could Misuse AI in Education</h2>
          <ul>
            <li><strong>Academic Dishonesty and Plagiarism:</strong>
              <ul>
                <li><strong>Submitting AI-Generated Work as Their Own:</strong> Using AI tools (like ChatGPT, Claude, Bard, or specialized essay/code generators) to produce essays, reports, code, solutions to problems, presentations, or other assignments and claiming authorship.</li>
                <li><strong>Automated Test/Quiz Taking:</strong> Employing AI bots or sophisticated AI tools to answer questions during online assessments, bypassing the need for personal knowledge and understanding.</li>
                <li><strong>Inadequate Paraphrasing and Citation:</strong> Using AI paraphrasing tools to superficially rewrite text from sources to avoid direct plagiarism detection, without truly understanding the material or properly citing the original ideas.</li>
                <li><strong>Fabricating Sources or Data:</strong> Instructing AI to generate plausible-sounding but fake references, research data, or quotes to support their work.</li>
                <li><strong>Deceptive Use in Collaborative Projects:</strong> Using AI to complete their individual contributions to group work without the knowledge or consent of their peers, misrepresenting their effort and learning.</li>
                <li><strong>Bypassing AI Detection Software:</strong> Actively seeking out and using techniques or tools designed to make AI-generated content appear human-written to evade detection.</li>
              </ul>
            </li>
            <li><strong>Circumventing Learning and Skill Development:</strong>
              <ul>
                <li><strong>Over-reliance for Instant Answers:</strong> Using AI as a constant crutch for immediate solutions, hindering the development of critical thinking, problem-solving skills, and deep understanding of concepts.</li>
                <li><strong>Avoiding Effortful Learning Processes:</strong> Skipping essential learning stages like research, drafting, and revision by offloading these tasks to AI.</li>
              </ul>
            </li>
            <li><strong>Deception and Impersonation:</strong>
              <ul>
                <li><strong>Automated Participation (Bots):</strong> Using AI bots to post generic comments or participate minimally in online discussion forums or virtual classes to feign engagement.</li>
                <li><strong>AI-Generated Avatars/Voice for Impersonation:</strong> (More advanced and less common currently, but a potential future misuse) Using AI to create fake profiles or mimic others in online interactions.</li>
              </ul>
            </li>
            <li><strong>Creating an Unfair Advantage:</strong>
              <ul>
                <li><strong>Access to Sophisticated/Paid AI Tools:</strong> Utilizing advanced or subscription-based AI tools that provide a significant advantage over peers who do not have similar access due to financial or other constraints.</li>
              </ul>
            </li>
            <li><strong>Disruption and Harm:</strong>
              <ul>
                <li><strong>Generating Inappropriate or Harmful Content:</strong> Using AI to create and distribute offensive, biased, harassing, or misleading content within the educational environment.</li>
                <li><strong>Creating Deepfakes:</strong> Generating fake images or videos of peers or educators for malicious purposes like bullying or defamation.</li>
              </ul>
            </li>
          </ul>
        </section>
        <section class="transparent-box">
          <h2 class="center-heading">Ways Teachers/Educators (and Institutions) Could Misuse AI</h2>
          <ul>
            <li><strong>Compromising Assessment Integrity and Fairness:</strong>
              <ul>
                <li><strong>Over-Reliance on AI Grading Without Oversight:</strong> Using AI tools to grade assignments (especially complex ones like essays or projects) without adequate human review, potentially leading to inaccurate, biased, or context-blind assessments.</li>
                <li><strong>Using Biased AI Grading Tools:</strong> Implementing AI grading systems that have inherent biases against specific demographic groups, writing styles, dialects, or students with disabilities, resulting in unfair evaluations.</li>
                <li><strong>Lack of Transparency in AI Assessment:</strong> Failing to inform students how AI is used in their assessment, what data is collected, and how they can appeal AI-driven decisions.</li>
              </ul>
            </li>
            <li><strong>Flawed Instruction and Curriculum Development:</strong>
              <ul>
                <li><strong>Distributing AI-Generated Content Without Vetting:</strong> Using AI to quickly create lesson plans, educational materials, or even exam questions that contain factual errors, outdated information, or biases, without thorough review and correction.</li>
                <li><strong>"Teaching to the Algorithm":</strong> Designing curriculum or teaching methodologies primarily to align with what AI tools can easily process or assess, rather than focusing on holistic student development and critical thinking.</li>
                <li><strong>Replacing Human Interaction with AI:</strong> Over-relying on AI tutors or chatbots to the detriment of meaningful student-teacher interaction, personalized feedback, and socio-emotional support.</li>
              </ul>
            </li>
            <li><strong>Violating Student Privacy and Data Mismanagement:</strong>
              <ul>
                <li><strong>Implementing Overly Intrusive AI Surveillance:</strong> Using AI-powered proctoring or monitoring tools that excessively track students (e.g., constant video/audio recording, biometric data collection, keystroke logging) without clear justification, informed consent, or robust data security measures.</li>
                <li><strong>Mishandling or Misusing Student Data:</strong> Collecting sensitive student data through AI platforms and using it for purposes beyond direct educational improvement (e.g., commercial exploitation, undisclosed profiling) or failing to secure it properly.</li>
                <li><strong>Lack of Transparency in Data Practices:</strong> Not clearly communicating to students and parents how their data is collected, stored, used, shared, and protected by AI systems used in the classroom.</li>
              </ul>
            </li>
            <li><strong>Perpetuating Inequity and Accessibility Issues:</strong>
              <ul>
                <li><strong>Mandating AI Tools with Unequal Access:</strong> Requiring the use of specific AI-powered educational tools or platforms that are not equally accessible to all students due to cost, technology requirements, or disabilities.</li>
                <li><strong>Deploying AI Not Designed for Accessibility:</strong> Using AI educational tools that are not compliant with accessibility standards, thereby creating barriers for students with disabilities.</li>
              </ul>
            </li>
            <li><strong>Eroding Professionalism and Autonomy:</strong>
              <ul>
                <li><strong>De-skilling Educators:</strong> Implementing AI systems in a way that overly automates pedagogical tasks, reducing the professional judgment, creativity, and autonomy of teachers.</li>
                <li><strong>Making High-Stakes Decisions Solely Based on AI:</strong> Using AI-driven analytics for critical decisions about students (e.g., promotion, disciplinary action, learning disability identification) without significant human oversight and contextual understanding.</li>
                <li><strong>Failing to Educate on Ethical AI Use:</strong> Not adequately preparing students (or fellow educators) on the ethical implications, responsible use, and limitations of AI technologies.</li>
                <li><strong>Generating Biased Recommendations or Evaluations:</strong> Using AI to write student recommendation letters or performance evaluations if the AI itself harbors biases or lacks nuanced understanding.</li>
              </ul>
            </li>
          </ul>
        </section>
      </div>
    </main>

    <footer>
      <p>Created by Cavin Krenik | ðŸ“§ <a href="mailto:cavinkrenik5@icloud.com">Contact Me</a></p>
    </footer>
  </div>
</body>
</html>
